{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div><img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> INF-493 - Machine Learning</h1>\n",
    "    <h1> Tarea 2 - Métodos para Clasificación </h1>\n",
    "</center>\n",
    "<p>\n",
    "<br><center>_Javier Reyes_<strong> - </strong>_javier.reyes.12@sansano.usm.cl_<strong> - </strong>_201273524-6_ </center>\n",
    "<br><center>_Marco Salinas_<strong> - </strong>_marco.salinas.12@sansano.usm.cl_<strong> - </strong>_201273589-0_ </center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1 Tipos de Fronteras en Clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "n_samples=500\n",
    "mean = (0,-4)\n",
    "C = np.array([[0.3, 0.1], [0.1, 1.5]])\n",
    "datos1 = np.random.multivariate_normal(mean, C, n_samples)\n",
    "outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples))*3\n",
    "outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples))*3\n",
    "datos2 = np.vstack((outer_circ_x,outer_circ_y)).T\n",
    "generator = check_random_state(10)\n",
    "datos2 += generator.normal(scale=0.3, size=datos2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(a)** Construya el conjunto de datos (dataset) común con los dos conjuntos generados. Luego se realiza un\n",
    "shift desde el conjunto 2 al 1, esto se puede ver en la imagen anterior, donde el conjunto de color\n",
    "naranjo (media luna) tiene puntos azules a la derecha pertenecientes al otro conjunto, esto es con\n",
    "el mismo propósito de trabajar con un dataset no ideal. Determine cuántos registros contiene cada\n",
    "conjunto y visualícelos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.concatenate((datos1, datos2), axis=0)\n",
    "n = 20 #ruido/noise\n",
    "y1 = np.zeros(datos1.shape[0]+n)\n",
    "y2 = np.ones(datos2.shape[0]-n) #media luna\n",
    "y = np.concatenate((y1,y2),axis=0)\n",
    "\n",
    "def plot(x,y):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.scatter(x[:,0], x[:,1], s=50, c=y, cmap=plt.cm.Set3)\n",
    "    plt.title(\"Distribución del dataset\")\n",
    "    plt.show()\n",
    "    \n",
    "plot(X,y)\n",
    "    \n",
    "print(\"El primer conjunto tiene \" + str(len(y1))\n",
    "     + \" datos \\nEl segundo conjunto tiene \" + str(len(y2)) + \" datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(b)** Entrene el clasificador Linear Discriminant Analysis (LDA) y visualice la frontera de decisión que\n",
    "define este algoritmo. Analice cualitativamente lo que observa.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_border(model,x,y,title=\"\"):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.scatter(x[:,0], x[:,1], s=50, c=y, cmap=plt.cm.Set3)\n",
    "    h = .02 # step size in the mesh\n",
    "    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.cool)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "model_LDA = LDA()\n",
    "model_LDA.fit(X,y)\n",
    "visualize_border(model_LDA,X,y,\"LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    Se puede observar que el conjuto de datos 1 esta separado de una manera uniforme, pero en uno de sus extremos se mezclan con los datos del conjunto 2, haciendo imposible una separación para discriminar los datos con el algoritmo de LDA (a través de una recta). La única manera de poder utilizar el clasificador, es eliminando los outlayers, aunque esto es muy riesgoso porque pueden ser información valiosa.\n",
    "</p>\n",
    "    \n",
    "<p  style=\"text-align: justify;\"> \n",
    "    **(c)** Entrene el clasificador Quadratic Discriminant Analysis (QDA) y visualice la frontera de decisión que define este algoritmo. Analice cualitativamente lo que observa y compare con LDA, en qué difieren y en qué se asemejan ¿Qué distribución de probabilidad asumen cada uno?\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "model_QDA = QDA()\n",
    "model_QDA.fit(X,y)\n",
    "visualize_border(model_QDA,X,y,\"QDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\"> \n",
    "    Al igual que en el caso de LDA, la separación entre ambos conjuntos es imposible, pero en este caso, QDA logra delimitar de mejor manera los conjutos integrando más datos al conjunto de datos azules. \n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    Comparación\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(d)** Compare cuantitativamente los clasificadores LDA y QDA en este dataset sintético mediante la métrica\n",
    "de error de clasificación.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_qda = model_QDA.predict(X)\n",
    "y_pred_lda = model_LDA.predict(X)\n",
    "print(\"Miss Classification Loss for LDA: %f\"%(1-accuracy_score(y, y_pred_lda)))\n",
    "print(\"Miss Classification Loss for QDA: %f\"%(1-accuracy_score(y, y_pred_qda)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\"> \n",
    "    **(e)** Construya una función que entrene/ajuste un modelo de Regresión Logística Regularizado (utilizando\n",
    "como penalizador la norma $l_2$), experimente con distintos valores del parámetro de regularización\n",
    "mediante el gráfico interactivo. Explique el significado y efecto esperado de este parámetro. Analice\n",
    "cualitativamente lo observado.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "def visualize_border_interactive(param):\n",
    "    model = train_model(param)\n",
    "    visualize_border(model,X,y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "def train_model(param):\n",
    "    model=LR(C=param,penalty='l2')\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "p_min = 0.01\n",
    "p_max = 1000\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 0.01))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(f)** Construya una función que entrene/ajuste una Máquina de Vectores de Soporte (SVM) Lineal. Mediante\n",
    "la imagen interactiva explore diferentes valores del parámetro de regularización C. Discuta el significado\n",
    "y efecto esperado de este parámetro. Analice cualitativamente lo observado.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC as SVM #SVC is for classification\n",
    "def train_model(param):\n",
    "    model= SVM()\n",
    "    model.set_params(C=param,kernel='linear')\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "#use interactive\n",
    "p_min = 0.0001\n",
    "p_max = 1\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(g)** Construya una función que entrene/ajuste una Máquina de Vectores de Soporte (SVM) no Lineal.\n",
    "Mediante la imagen interactiva explore diferentes valores del parámetro de regularización C y con\n",
    "diferentes kernels. Discuta el significado y efecto esperado de este parámetro. Analice cualitativamente\n",
    "lo observado.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(param):\n",
    "    model= SVM()\n",
    "    model.set_params(C=param,kernel='rbf')\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "#use interactive\n",
    "p_min = 1\n",
    "p_max = 100\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(h)** Construya un Arbol de Decisión de múltiples niveles para la clasificación del problema. Puede utilizar el criterio y la función de partición que prefiera. Mediante la imagen interactiva explore diferentes\n",
    "valores del parámetro de máxima profunidad del árbol. Discuta el significado y efecto esperado de este\n",
    "parámetro. Analice cualitativamente lo observado.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "\n",
    "\n",
    "def train_model(param):\n",
    "    model = Tree() #edit the train_model function\n",
    "    model.set_params(max_depth=param,criterion='gini',splitter='best')\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "#use interactive\n",
    "p_min = 1\n",
    "p_max = 100\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(i)** Construya un algoritmo $k-NN$ para la clasificación del problema. Mediante la imagen interactiva explore\n",
    "diferentes valores del parámetro $k$. Discuta el significado y efecto esperado de este parámetro. Analice\n",
    "cualitativamente lo observado.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_model(param):\n",
    "    model = KNeighborsClassifier()\n",
    "    model.set_params(n_neighbors=param)\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "\n",
    "p_min = 1\n",
    "p_max = 20\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Análisis de audios como datos brutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    En esta parte de la experencia se trabajará con datos de audios los cuales son directamente extraídos desde datos fuentes _.wav_, lo que corresponde a una señal de sonido en diferentes tiempos. El _dataset_ se denomina _ Heartbeat Sounds_, el cual consta de grabaciones de sonidos de latidos cardíacos normales y anormales, con distintas categorías para los latidos anormales. Los datos fueron obtenidos desde un publico general a través de la aplicación de iPhone iStethoscope Pro.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "def clean_filename(fname, string):\n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':\n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "def load_wav_file(name, path):\n",
    "    s, b = wavfile.read(path + name)\n",
    "    assert s == SAMPLE_RATE\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(a)** Construya un dataframe con los datos a analizar. Describa el dataset y determine cuántos registros hay\n",
    "por clase.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./heartbeat-sounds/set_a.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    El _dataset_ posee 176 datos, los cuales poseen 4 columnas cada uno.\n",
    "    <ul style=\"list-style-type:disc;margin-left:24px\">\n",
    "        <li>**dataset:** columna que indica a que dataset corresponde el dato</li>\n",
    "        <li>**fname:** corresponde al nombre del archivo de audio</li>\n",
    "        <li>**label:** puede ser \"normal\", estar en blanco (para datos sin etiqueta), y anormales donde pueden ser \"artifac\", \"extrahls\" y \"murmur\". </li>\n",
    "        <li>**sublabel:** columna sin datos.</li>\n",
    "\n",
    "    </ul>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    Descripcion de las categorias:\n",
    "    <ul style=\"list-style-type:disc;margin-left:24px;text-align: justify;\">\n",
    "        <li>**Normal:** Corresponden a sonidos de corazones normales y saludables.</li>\n",
    "        <li>**Murmur (Soplo):** Corresponden a soplos cardíacos, que suenan como si hubiera un ruido de \"silbido, rugido, estruendo o fluido turbulento\". </li>\n",
    "        <li>**Extra Heart Sound:** Correspoden a una medición en la cual se escucha un sonido adicional del corazón.  </li>\n",
    "        <li>**Artifact:** En esta categoria se encuentra una amplia gama de sonidos diferentes, que incluyen chillidos y ecos de realimentación, voz, música y ruido. Gerenalmente no hay sonidos cardíacos discernibles. Esta categoría es la más diferente de las otras. </li>\n",
    "        <li>**Unlabelled:** Son aquellas muestras que no estan etiquetadas en ninguna categoria. </li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "|     Categoria     \t| Registro \t|\n",
    "|:-----------------:\t|:--------:\t|\n",
    "|       Normal      \t|    31    \t|\n",
    "|       Murmur      \t|    34    \t|\n",
    "| Extra Heart Sound \t|    19    \t|\n",
    "|      Artifact     \t|    40    \t|\n",
    "|     Unlabelled    \t|    52    \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['dataset','sublabel',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Artifact\",df.label.value_counts()['artifact'])\n",
    "print(\"Murmur\", df.label.value_counts()['murmur'])\n",
    "print(\"Extra Heart Sound\", df.label.value_counts()['extrahls'])\n",
    "print(\"Normal\", df.label.value_counts()['normal'])\n",
    "print(\"Unlabelled\", 176-40-34-19-31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(b)** Lea los archivos _.wav_ y transformelos en secuencias de tiempo. Realice un _padding_ de ceros al final de\n",
    "cada secuencia para que todas queden representadas con la misma cantidad de elementos, explique la\n",
    "importancia de realizar este paso.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padd_zeros(array,length):\n",
    "    aux = np.zeros(length)\n",
    "    aux[:array.shape[0]] = array\n",
    "    return aux\n",
    "\n",
    "\n",
    "new_df =pd.DataFrame({'file_name' : df['fname'].apply(clean_filename,string='Aunlabelledtest')})\n",
    "new_df['time_series'] = new_df['file_name'].apply(load_wav_file, path='./heartbeat-sounds/set_a/')\n",
    "new_df['len_series'] = new_df['time_series'].apply(len)\n",
    "new_df['time_series'] = new_df['time_series'].apply(padd_zeros,length=max(new_df['len_series']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(c)** Manipule los datos y cambie las etiquetas de los audios por otras asignadas por un doctor experto,\n",
    "el cual afirma que estos cambios son requeridos. Vuelva a determinar cuántos registros hay por clase.\n",
    "Nótese que ahora son 3 clases ¿Explique la problemática de tener etiquetas mal asignadas en los datos?\n",
    "¿Un solo dato puede afectar esto?\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "             1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
    "             2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
    "             1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0,\n",
    "             2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0, 0, 0,\n",
    "             0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "labels = ['artifact','normal/extrahls', 'murmur']\n",
    "new_df['target'] = [labels[i] for i in new_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Artifact\",new_df.target.value_counts()['artifact'])\n",
    "print(\"Murmur\", new_df.target.value_counts()['murmur'])\n",
    "print(\"Normal and EHSound\", new_df.target.value_counts()['normal/extrahls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          Categoria         \t| Registro \t|\n",
    "|:--------------------------:\t|:--------:\t|\n",
    "| Normal / Extra Heart Sound \t|    65    \t|\n",
    "|           Murmur           \t|    53    \t|\n",
    "|          Artifact          \t|    58    \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(d)**  Codifique las distintas clases a valores numéricos para que puedan ser trabajados por los algoritmos\n",
    "clasificadores.\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df[\"target\"] = new_df[\"target\"].astype('category')\n",
    "cat_columns = new_df.select_dtypes(['category']).columns\n",
    "new_df[cat_columns] = new_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(e)** Desordene los datos, evitando así el orden en el que vienen la gran mayoría de las etiquetas. Cree la\n",
    "matriz que conforma a los datos en sus dimensiones sin preprocesar, es decir, cada ejemplo es una\n",
    "secuencia de amplitudes en el tiempo. ¿Las dimensiones de ésta indica que puede generar problemas?\n",
    "¿De qué tipo?\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = new_df.sample(frac=1,random_state=44)\n",
    "X = np.stack(new_df['time_series'].values, axis=0)\n",
    "y = new_df.target.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(f)** Para pre procesar la secuencia en el tiempo realice una Transformada de Fourier discreta para pasar\n",
    "los datos desde el dominio de tiempos al dominio de frecuencias presentes en la señal de sonido.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fourier = np.abs(np.fft.fft(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(g)**  Para seguir con el pre procesamiento realice un muestreo representativo de los datos a través de una\n",
    "técnica de muestreo especializada en secuencias ¿En qué beneficia este paso? ¿Cómo podría determinar\n",
    "si el muestro es representativo?\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "X_resampled = []\n",
    "for i in range(X_fourier.shape[0]):\n",
    "    sequence = X_fourier[i,:].copy()\n",
    "    resampled_sequence = signal.resample(sequence, 100000)\n",
    "    X_resampled.append(resampled_sequence)\n",
    "\n",
    "X_resampled = np.array(X_resampled)\n",
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(h)**  Genere un conjunto de pruebas mediante la técnica _hold-out validation_ para verificar la calidad de los\n",
    "clasificadores. ¿Cuántas clases tiene y de qué tamaño queda cada conjunto?\n",
    "\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y, test_size=0.25, random_state=43)\n",
    "\n",
    "print(\"El set de entrenamiento tiene \" + str(len(X_train)) \n",
    "      + \" y el set de test tiene \" + str(len(X_test)) \n",
    "      + \" datos, y ambos tienen 10000 clases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(i)**  Realice un proceso de estandarizar los datos para ser trabajados adecuadamente. Recuerde que solo se\n",
    "debe ajustar (calcular media y desviación estándar) con el conjunto de entrenamiento.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(j)**  Realice una reducción de dimensionalidad a través de la técnica PCA, para representar los datos en $d = 2$ dimensiones. Recuerde que solo se debe ajustar (encontrar las componentes principales) con el conjunto de entrenamiento. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "d=2\n",
    "pca_model = PCA(n_components=d)\n",
    "pca_model.fit(X_train)\n",
    "X_pca_train = pca_model.transform(X_train)\n",
    "X_pca_test = pca_model.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(k)**  Entrene un modelo de Regresión Logística variando el parámetro de regularización $C$ construyendo un gráfico resumen del error en función de este hiper-parámetro. Además entrene una Máquina de Soporte Vectorial (SVM) con kernel lineal, variando el hiper-parámetro de regularizacion $C$ en el mismo rango que para la Regresión Logística, construyendo el mismo gráfico resumen. Compare.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC as SVM #SVC is for classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mse_LR_train = []\n",
    "mse_LR_test = []\n",
    "\n",
    "mse_SVM_train = []\n",
    "mse_SVM_test = []\n",
    "\n",
    "Ks = []\n",
    "Ks_ticks = [0.0001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "for i, Cs in enumerate((0.0001,0.01,0.1,1,10,100,1000)):\n",
    "    \n",
    "    model_LR = LR(C=Cs)\n",
    "    model_SVM = SVM(C=Cs)\n",
    "    \n",
    "    model_LR.fit(X_pca_train, y_train)\n",
    "    model_SVM.fit(X_pca_train, y_train)\n",
    "    \n",
    "    y_pred_LR_train = model_LR.predict(X_pca_train)\n",
    "    y_pred_LR_test = model_LR.predict(X_pca_test)\n",
    "    \n",
    "    y_pred_SVM_train = model_SVM.predict(X_pca_train)\n",
    "    y_pred_SVM_test = model_SVM.predict(X_pca_test)\n",
    "\n",
    "    mse_LR_train.append(1-accuracy_score(y_train, y_pred_LR_train))\n",
    "    mse_LR_test.append(1-accuracy_score(y_test, y_pred_LR_test))\n",
    "    \n",
    "    mse_SVM_train.append(1-accuracy_score(y_train, y_pred_SVM_train))\n",
    "    mse_SVM_test.append(1-accuracy_score(y_test, y_pred_SVM_test))\n",
    "    \n",
    "    Ks.append(i+1)\n",
    "    \n",
    "    #print(\"Miss Classification Loss for LR: %f\"%(1-accuracy_score(y_train, y_pred_LR)))\n",
    "    #print(\"Miss Classification Loss for SVM: %f\"%(1-accuracy_score(y_train, y_pred_SVM)))\n",
    "    \n",
    "    #print(\"C=%.5f\" % Cs)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "LR_plot = plt.subplot(2,1,1)\n",
    "LR_plot.plot(Ks, mse_LR_train, label='Training Misclassification Error')\n",
    "LR_plot.plot(Ks, mse_LR_test, label='Testing Misclassification Error')\n",
    "plt.legend(loc=3)\n",
    "plt.ylabel('Miss Classification Error')\n",
    "plt.axis([1,6,0.0, 0.7])\n",
    "plt.xticks(Ks, Ks_ticks)\n",
    "\n",
    "SVM_plot = plt.subplot(2,1,2)    \n",
    "SVM_plot.plot(Ks, mse_SVM_train, label = 'Training Misclassification Error')\n",
    "SVM_plot.plot(Ks, mse_SVM_test, label = 'Test Misclassification Error')\n",
    "plt.legend(loc=3)\n",
    "plt.xlabel('Parámetro Regularizador $C$')\n",
    "plt.ylabel('Miss Classification Error')\n",
    "plt.axis([1,6,0.0, 0.7])\n",
    "plt.xticks(Ks, Ks_ticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.xlabel('Parametro Regularización $C$')\n",
    "#plt.ylabel('Miss Classification Error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(l)**  Entrene un Arbol de Decisión, con la configuración que estime conveniente, variando el hiper-parámetro regularizador _max depth_, construyendo un gráfico resumen del error en función de este parámetro.\n",
    "Compare con los modelos anteriores.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "Depths = range(1,30)\n",
    "\n",
    "mse_DTC_train = []\n",
    "mse_DTC_test = []\n",
    "\n",
    "for i in Depths:\n",
    "    model_DTC = DTC(max_depth = i)\n",
    "    \n",
    "    model_DTC.fit(X_pca_train, y_train)\n",
    "    \n",
    "    y_pred_DTC_train = model_DTC.predict(X_pca_train)\n",
    "    y_pred_DTC_test = model_DTC.predict(X_pca_test)\n",
    "    \n",
    "    mse_DTC_train.append(1-accuracy_score(y_train, y_pred_DTC_train))\n",
    "    mse_DTC_test.append(1-accuracy_score(y_test, y_pred_DTC_test))\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "DTC_plot = plt.subplot(1,1,1)\n",
    "DTC_plot.plot(Depths, mse_DTC_train, label='Training Misclassification Error')\n",
    "DTC_plot.plot(Depths, mse_DTC_test, label='Testing Misclassification Error')\n",
    "plt.legend(loc=3)\n",
    "plt.ylabel('Miss Classification Error')\n",
    "plt.axis([0,30,0.0, 0.7])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(m)**  Experimente con diferentes dimensiones $d$ para la proyección de PCA con el propósito de obtener un\n",
    "modelo con menor error. Construya una tabla o gráfico resumen.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "mse_dim_train = []\n",
    "mse_dim_test = []\n",
    "\n",
    "for d in range(1,10):\n",
    "    pca_model = PCA(n_components=d)\n",
    "    pca_model.fit(X_train)\n",
    "    X_pca_train = pca_model.transform(X_train)\n",
    "    X_pca_test = pca_model.transform(X_test)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(n)**  Realice otra reducción de dimensionalidad ahora a través de la técnica LDA, para representar los datos en $d = 2$ dimensiones. Recuerde que sólo se debe ajustar con el conjunto de entrenamiento, si se muestra un warning explique el porqué. Visualice apropiadamente la proyección en $2$ dimensiones.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "model_lda = LDA(n_components=2)\n",
    "model_lda.fit(X_train,y_train)\n",
    "X_pca_train = model_lda.transform(X_train)\n",
    "X_pca_test = model_lda.transform(X_test)\n",
    "print(X_pca_train.shape)\n",
    "\n",
    "plot(X_pca_train, y_train)\n",
    "plot(X_pca_test, y_test)\n",
    "\n",
    "#y_pred_lda = model_lda.predict(X_pca_train)\n",
    "\n",
    "#visualize_border(model_lda, X_train, y_train,\"LDA\")\n",
    "#print(X_pca_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(o)**  Con el propósito de encontrar el mejor modelo vuelva a realizar el item h) con el i) en el nuevo espacio generado por la representación según las d dimensiones de la proyección LDA. Esta nueva representación ¿mejora o empeora el desempeño? Explique.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(p)**  Intente mejorar el desempeño de los algoritmos ya entrenados. Diseñe ahora sus propias características (_feature crafting_) a partir de los datos brutos (secuencia de amplitudes), puede inspirarse en otros trabajos [6] [7] si desea.\n",
    "</p>\n",
    "\n",
    "- [6]  https://www.kaggle.com/primaryobjects/voicegender/data\n",
    "- [7]  Gamit, M. R., Dhameliya, P. K., & Bhatt, N. S. (2015). Classification Techniques for Speech Recognition: A Review. vol, 5, 58-63.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Análisis de emociones en tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(a)**  Construya un dataframe con los datos a analizar. Determine cuántas clases existen, cuántos registros por clase y describa el _dataset_.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_csv('./text_emotion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Sentimiento | Registro |\n",
    "|:-----------:|:--------:|\n",
    "|   Neutral   |   8638   |\n",
    "|    Worry    |   8459   |\n",
    "|  Happiness  |   5209   |\n",
    "|   Sadness   |   5165   |\n",
    "|     Love    |   3842   |\n",
    "|   Surprise  |   2187   |\n",
    "|     Fun     |   1776   |\n",
    "|    Relief   |   1526   |\n",
    "|     Hate    |   1323   |\n",
    "|    Empty    |    827   |\n",
    "|  Enthusiasm |    759   |\n",
    "|   Boredom   |    179   |\n",
    "|    Anger    |    110   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(b)**  Construya un conjunto de entrenamiento y otro de pruebas, a través de una máscara aleatoria, para verificar los resultados de los algoritmos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(22)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y, test_size=0.25, random_state=43)\n",
    "\n",
    "#print(df['content'][2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(c)**  Implemente y explique un pre-procesamiento para los tweets para dejarlos en un formato estándarizado\n",
    "en el cual se podrán trabajar.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['tweet_id','author'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\[\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "\n",
    "\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "#print(preprocess(df['content'][0]))\n",
    "\n",
    "#df['content'] = df['content'].str\n",
    "df['content'] = df['content'].apply(preprocess)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"rt\",\"via\",\"a\",\"able\",\"about\",\"across\",\"after\",\"all\",\"almost\",\"also\",\"am\",\"among\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"but\",\"by\",\"can\",\"cannot\",\"could\",\"dear\",\"did\",\"do\",\"does\",\"either\",\"else\",\"ever\",\"every\",\"for\",\"from\",\"get\",\"got\",\"had\",\"has\",\"have\",\"he\",\"her\",\"hers\",\"him\",\"his\",\"how\",\"however\",\"i\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"least\",\"let\",\"like\",\"likely\",\"may\",\"me\",\"might\",\"most\",\"must\",\"my\",\"neither\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"often\",\"on\",\"only\",\"or\",\"other\",\"our\",\"own\",\"rather\",\"said\",\"say\",\"says\",\"she\",\"should\",\"since\",\"so\",\"some\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\"these\",\"they\",\"this\",\"tis\",\"to\",\"too\",\"twas\",\"us\",\"wants\",\"was\",\"we\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"would\",\"yet\",\"you\",\"your\"]\n",
    "stop = stopwords.words('english')\n",
    "result = list(set(stop)|set(stop_words)|set(list('abcdefghijklmnopqrstuvwxyz')) | set(list('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')) | set(list('0123456789')))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: [item for item in x if item not in result])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(d)**  Haga una reducción binaria al problema, para trabajarlo como un problema de clasificación de dos clases.\n",
    "Para esto, agrupe las distintas emociones como positivas y negativas (defina un criterio), se recomienda\n",
    "codificar las clases como +1 y −1 respectivamente. Recuerde tener presente que el desbalanceo de los\n",
    "datos puede afectar considerablemente al modelo.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uno = ['neutral', 'happiness', 'love', 'fun', 'relief', 'enthusiasm']\n",
    "\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x in uno else -1)\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(e)**  Para construir un clasificador que determine automáticamente la polaridad de un trozo de texto, será\n",
    "necesario representar los tweets $\\{t_i\\}_{i=1}^{n}$ disponibles como vectores de características (features). El tipo\n",
    "de características más utilizado consiste en contar cuántas veces aparecen ciertos términos/palabras en\n",
    "el texto. Para esto, es necesario un vocabulario que, por lo general, se construye mediante la unión de\n",
    "todas las palabras que se observen en los tweets.\n",
    "\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\">\n",
    "Se recomienda utilizar las librerías ofrecidas por sklearn de feature extraction in text [12] (_CountVectorizer_ y _TfidfVectorizer_). Recuerde realizar el ajuste (_fit_) únicamente con el conjunto de entrenamiento, para luego transformar el conjunto de pruebas (con el método transform).\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "- [12] http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df['content'].values\n",
    "y = df.sentiment.values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "CV_model = CountVectorizer(input=X_train, lowercase=False, preprocessor=None, tokenizer=None, stop_words=None)\n",
    "CV_model.fit(X_train)\n",
    "X_CV_train = CV_model.transform(X_train)\n",
    "X_CV_test = CV.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(f)**  Entrene y compare al menos 5 de los diferentes clasificadores vistos en clases para clasificación binaria (por ejemplo: Navie Bayes, Multinomial Naive Bayes, LDA, QDA, Regresión logística, SVM y Arboles de decisión) sobre el conjunto de entrenamiento verificando su desempeño sobre ambos conjuntos (entrenamiento y de pruebas), construyendo un gráfico resumen del error de éstos.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(g)**  Utilice y explique las métricas que calcula la función classification report de la librería sklearn. En base\n",
    "a las distintas métricas calculadas ¿Cuáles clasificadores son los que mejor se comportan?\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy: %f\"%(acc_tr)\n",
    "    print \"Test Accuracy: %f\"%(acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(y_test, model.predict(X_test), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(h)**  [Opcional] Visualice las predicciones de algún modelo generativo (probabilístico) definido anteriormente, tomando un subconjunto aleatorio de tweets de pruebas y explorando las probabilidades que asigna el clasificador a cada clase.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict_proba(X_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(df_test.content[spl], test_pred[spl]):\n",
    "    print sentiment, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(i)**  Ahora deberá extender el problema a las múltiples clases que tiene presente (las distintas emociones),\n",
    "es decir, su trabajo será el de predecir una de las distintas emociones de cada _tweet_. Para esto utilice el\n",
    "mismo pre-procesamiento realizado en el punto c) y las características generadas mediante las técnicas\n",
    "en el punto e). Recuerde que tendrá que codificar las distintas clases como valores numéricos enteros.\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(j)**  Utilice los clasificadores que son extendidos por defecto a múltiples clases para detectar emociones en\n",
    "cada _tweet_, muestre sus desempeños a través del error de pruebas en un gráfico resumen.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(k)**  Utilice clasificadores binarios que pueden ser extendidos a través de otras técnicas, tal como One vs\n",
    "One y One vs All/Rest [14]\n",
    "</p>\n",
    "\n",
    "- [14]  http://scikit-learn.org/stable/modules/classes.html#module-sklearn.multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "#example\n",
    "classif = OneVsRestClassifier(model)\n",
    "classif.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(l)**  Para el caso de la Regresión Logística compare sus dos métodos para ser extendidos a múltiples clases.\n",
    "Uno a través de One vs Rest y otro definiendo que la variable a predecir se distribuye Multinomial.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LogisticRegression(multi_class='ovr')\n",
    "LogisticRegression(multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(m)**  Compare los resultados entre los clasificadores extendidos por defecto y los binarios que son extendidos mediante otras técnicas, construya una tabla o gráfico resumen. Los clasificadores que mejor se comportan en el caso binario ¿Siguen teniendo ese desempeño en múltiples clases?\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
