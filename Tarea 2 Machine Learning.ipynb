{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div><img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> INF-493 - Machine Learning</h1>\n",
    "    <h1> Tarea 2 - Métodos para Clasificación </h1>\n",
    "\n",
    "<p>\n",
    "<br><center>_Javier Reyes_<strong> - </strong>_javier.reyes.12@sansano.usm.cl_<strong> - </strong>_201273524-6_ </center>\n",
    "<br><center>_Marco Salinas_<strong> - </strong>_marco.salinas.12@sansano.usm.cl_<strong> - </strong>_201273589-0_ </center>\n",
    "</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1 Tipos de Fronteras en Clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "n_samples=500\n",
    "mean = (0,-4)\n",
    "C = np.array([[0.3, 0.1], [0.1, 1.5]])\n",
    "datos1 = np.random.multivariate_normal(mean, C, n_samples)\n",
    "outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples))*3\n",
    "outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples))*3\n",
    "datos2 = np.vstack((outer_circ_x,outer_circ_y)).T\n",
    "generator = check_random_state(10)\n",
    "datos2 += generator.normal(scale=0.3, size=datos2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(a)** Construya el conjunto de datos (dataset) común con los dos conjuntos generados. Luego se realiza un\n",
    "shift desde el conjunto 2 al 1, esto se puede ver en la imagen anterior, donde el conjunto de color\n",
    "naranjo (media luna) tiene puntos azules a la derecha pertenecientes al otro conjunto, esto es con\n",
    "el mismo propósito de trabajar con un dataset no ideal. Determine cuántos registros contiene cada\n",
    "conjunto y visualícelos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.concatenate((datos1, datos2), axis=0)\n",
    "n = 20 #ruido/noise\n",
    "y1 = np.zeros(datos1.shape[0]+n)\n",
    "y2 = np.ones(datos2.shape[0]-n) #media luna\n",
    "y = np.concatenate((y1,y2),axis=0)\n",
    "\n",
    "def plot(x,y):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.scatter(x[:,0], x[:,1], s=50, c=y, cmap=plt.cm.Set3)\n",
    "    plt.title(\"Distribución del dataset\")\n",
    "    plt.show()\n",
    "    \n",
    "plot(X,y)\n",
    "    \n",
    "print(\"El primer conjunto tiene \" + str(len(y1))\n",
    "     + \" datos \\nEl segundo conjunto tiene \" + str(len(y2)) + \" datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(b)** Entrene el clasificador Linear Discriminant Analysis (LDA) y visualice la frontera de decisión que\n",
    "define este algoritmo. Analice cualitativamente lo que observa.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.mlab as mlab\n",
    "def visualize_border(model,x,y,title=\"\"):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.scatter(x[:,0], x[:,1], s=50, c=y, cmap=plt.cm.Set3)\n",
    "    h = .02 # step size in the mesh\n",
    "    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.cool)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "model_LDA = LDA()\n",
    "model_LDA.fit(X,y)\n",
    "visualize_border(model_LDA,X,y,\"LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    Se puede observar que el conjuto de datos 1 esta separado de una manera uniforme, pero en uno de sus extremos se mezclan con los datos del conjunto 2, haciendo imposible una separación para discriminar los datos con el algoritmo de LDA (a través de una recta). La única manera de poder utilizar el clasificador, es eliminando los outlayers, aunque esto es muy riesgoso porque pueden ser información valiosa.\n",
    "</p>\n",
    "    \n",
    "<p  style=\"text-align: justify;\"> \n",
    "    **(c)** Entrene el clasificador Quadratic Discriminant Analysis (QDA) y visualice la frontera de decisión que define este algoritmo. Analice cualitativamente lo que observa y compare con LDA, en qué difieren y en qué se asemejan ¿Qué distribución de probabilidad asumen cada uno?\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "import math as ma\n",
    "model_QDA = QDA()\n",
    "model_QDA.fit(X,y)\n",
    "visualize_border(model_QDA,X,y,\"QDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\"> \n",
    "    Al igual que en el caso de LDA, la separación entre ambos conjuntos es imposible, pero en este caso, QDA logra delimitar de mejor manera los conjutos integrando más datos al conjunto de datos azules. \n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    <ul>\n",
    "        <li>Semejanzas\n",
    "            <ul>\n",
    "                <li>Ambos métodos de clasificación no pueden separar en un 100% el conjunto de datos.</li>\n",
    "                <li>Aunque el tipo de separación es distinta, la cantidad de puntos que separan es prácticamente la misma.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Diferencias\n",
    "            <ul>\n",
    "                <li>El tipo de separación para clasificar los datos es distinta: LDA - línea recta; QDA - parábola.</li>\n",
    "                <li>QDA prioriza la separación en donde está más centrado un tipo de datos, mientras que LDA tiende a separar a la \"mitad\" el dataset.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\">\n",
    "    Tanto LDA como QDA asumen una distribución de probabilidad normal o Gaussiana.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(d)** Compare cuantitativamente los clasificadores LDA y QDA en este dataset sintético mediante la métrica\n",
    "de error de clasificación.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_qda = model_QDA.predict(X)\n",
    "y_pred_lda = model_LDA.predict(X)\n",
    "print(\"Miss Classification Loss for LDA: %f\"%(1-accuracy_score(y, y_pred_lda)))\n",
    "print(\"Miss Classification Loss for QDA: %f\"%(1-accuracy_score(y, y_pred_qda)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(e)** Construya una función que entrene/ajuste un modelo de Regresión Logística Regularizado (utilizando\n",
    "como penalizador la norma $l_2$), experimente con distintos valores del parámetro de regularización\n",
    "mediante el gráfico interactivo. Explique el significado y efecto esperado de este parámetro. Analice\n",
    "cualitativamente lo observado.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "def visualize_border_interactive(param):\n",
    "    model = train_model(param)\n",
    "    visualize_border(model,X,y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "def train_model(param):\n",
    "    model=LR(C=param,penalty='l2')\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "p_min = 0.01\n",
    "p_max = 1\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\"> \n",
    "Al aplicar la penalización con la norma $l_2$, lo que hace la $Logistic Regression$ es ir penalizando los datos con la regla de $Lasso$, es decir, que a mayor $\\lambda$ mayor es la penalización. Es por esto que al aumentar la penalización, los límites de separación se irán ajustando de manera que quede lo más equilibrado posible, aunque esto implique \"pasarse\" un poco de la pendiente normal que tenía la recta al utilizar LDA.\n",
    "<br>\n",
    "Como se puede observar, en $p_{min}$ se obtiene la separación con LDA y mientras aumenta el valor de la penalización hasta llegar al valor $p_{max}$ se tendrá la \"mejor\" separación o la más equitativa entre los datos. Notar que llegando al valor $p = 0.6$ luego si se sigue aumentando el valor de $p$, la pendiente de la recta no aumentará, por lo que se llegá a la mejor separación entre los límites de los conjuntos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(f)** Construya una función que entrene/ajuste una Máquina de Vectores de Soporte (SVM) Lineal. Mediante\n",
    "la imagen interactiva explore diferentes valores del parámetro de regularización C. Discuta el significado\n",
    "y efecto esperado de este parámetro. Analice cualitativamente lo observado.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC as SVM #SVC is for classification\n",
    "def train_model(param):\n",
    "    model= SVM()\n",
    "    model.set_params(C=param,kernel='linear')\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "#use interactive\n",
    "p_min = 0.0001\n",
    "p_max = 1\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\"> \n",
    "Las $SMV$ se caracterizan por maximizar la mínima distancia de un punto de un conjuto al hiperplano, por lo que en este caso, se tendrá que aplicar el parámetro $C$ para poder clasificar de una mejor manera los datos. La función que cumple el parámetro $C$ es similar a la norma $l_2$ en $Logistic Regression$, ya que este se encarga de decirle a la $SVM$ cuántos datos mal clasificados quieres evitar. Si se tiene un $C$ pequeño, se tendrá un mayor margen de la separación al hiperplano incluso si hay elementos mal clasificados, en cambio con un $C$ grande, la $SVM$ buscará el margen al hiperplano más pequeño.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(g)** Construya una función que entrene/ajuste una Máquina de Vectores de Soporte (SVM) no Lineal.\n",
    "Mediante la imagen interactiva explore diferentes valores del parámetro de regularización C y con\n",
    "diferentes kernels. Discuta el significado y efecto esperado de este parámetro. Analice cualitativamente\n",
    "lo observado.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_border_interactive(param, kernel):\n",
    "    model = train_model(param, kernel)\n",
    "    visualize_border(model,X,y)\n",
    "\n",
    "def train_model(param, kernel):\n",
    "    model= SVM()\n",
    "    model.set_params(C=param,kernel=kernel)\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "#use interactive\n",
    "p_min = 1\n",
    "p_max = 100\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 1), kernel = ['rbf','poly','linear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    <ul>\n",
    "        <li>C - RBF: Para el kernel <i>Radial Basic Function</i>, lo que hace $C$ es disminuir el \"radio\" que encierra al conjunto de datos amarillo. $C$ actúa de la misma manera anteriormente descrita, por lo que a un mayor $C$, el \"radio\" será menor.\n",
    "        </li>\n",
    "        <li>C - Poly: Para el kernel <i>Polinomial</i>, lo que hace $C$ es ir ajustando el polinomio a la separación óptima de los conjuntos de datos\n",
    "        </li>\n",
    "        <li>C - Linear: Es una $SVM$ normal, se discutió en la pregunta anterior.\n",
    "        </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(h)** Construya un Arbol de Decisión de múltiples niveles para la clasificación del problema. Puede utilizar el criterio y la función de partición que prefiera. Mediante la imagen interactiva explore diferentes\n",
    "valores del parámetro de máxima profunidad del árbol. Discuta el significado y efecto esperado de este\n",
    "parámetro. Analice cualitativamente lo observado.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "def visualize_border_interactive(param,criterion):\n",
    "    model = train_model(param,criterion)\n",
    "    visualize_border(model,X,y)\n",
    "\n",
    "def train_model(param,criterion):\n",
    "    model = Tree() #edit the train_model function\n",
    "    model.set_params(max_depth=param,criterion='entropy',splitter='best')\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X)\n",
    "    print (\"Accuracy is : {0:.1f}%\".format(accuracy_score(y,y_pred)*100))\n",
    "    return model\n",
    "\n",
    "#use interactive\n",
    "p_min = 1\n",
    "p_max = 20\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max, 1),criterion = ['gini','entropy','variance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\"> \n",
    "    En este caso, los 3 criterios $gini$,$entropy$ y $variance$ se comportan de la misma manera en el Árbol de decisión. Lo que permite una mayor profundización en el árbol, es tener tantas separaciones de tal manera de obtener un conjunto de datos dentro de un espacio $A$ y otro en el espacio $B$, es decir, encacillar los conjuntos de datos.\n",
    "    <br>\n",
    "    Para este caso, el valor máximo de profundidad es $h_{max} = 11$ en donde se obtiene un 100% de acierto al separar el conjunto de datos amarillos del azul. Al seguir aumentando la cantidad de profundidad, lo único que se logra es separar los datos de otra manera.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(i)** Construya un algoritmo $k-NN$ para la clasificación del problema. Mediante la imagen interactiva explore\n",
    "diferentes valores del parámetro $k$. Discuta el significado y efecto esperado de este parámetro. Analice\n",
    "cualitativamente lo observado.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def visualize_border_interactive(param):\n",
    "    model = train_model(param)\n",
    "    visualize_border(model,X,y)\n",
    "\n",
    "def train_model(param):\n",
    "    model = KNeighborsClassifier()\n",
    "    model.set_params(n_neighbors=param)\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X)\n",
    "    print (\"Accuracy is : {0:.1f}%\".format(accuracy_score(y,y_pred)*100))\n",
    "    return model\n",
    "\n",
    "\n",
    "k_min = 1\n",
    "k_max = 20\n",
    "interactive(visualize_border_interactive,param=(k_min,k_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    Analisis Cualitativo.\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\"> \n",
    "La fase de entrenamiento del algoritmo consiste en almacenar los vectores característicos y las etiquetas de las clases de los ejemplos de entrenamiento. En la fase de clasificación, la evaluación del ejemplo (del que no se conoce su clase) es representada por un vector en el espacio característico. Se calcula la distancia entre los vectores almacenados y el nuevo vector, y se seleccionan los $k$ ejemplos más cercanos. El nuevo ejemplo es clasificado con la clase que más se repite en los vectores seleccionados, es por esto que al aumentar la cantidad de vecinos $k$, el ruido o sesgo de los datos debería disminuir, aunque depende netamente de los datos.\n",
    "<br>\n",
    "EL algoritmo $k-NN$ actúa localmente buscando los vecinos más cercanos, los cuales se espera nos den la mejor clasificación. Para este caso, basta tomar $k = 1$ para obtener una separación perfecta entre los conjuntos de datos, ya que a medida de que se aumenta el número de vecino $k$, el porcentaje de acierto de clasificación llega como máximo al $98.5\\%$. Notar que cuando los vecinos son impares, el porcentaje de acierto es más alto. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Análisis de audios como datos brutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    En esta parte de la experencia se trabajará con datos de audios los cuales son directamente extraídos desde datos fuentes _.wav_, lo que corresponde a una señal de sonido en diferentes tiempos. El _dataset_ se denomina _ Heartbeat Sounds_, el cual consta de grabaciones de sonidos de latidos cardíacos normales y anormales, con distintas categorías para los latidos anormales. Los datos fueron obtenidos desde un publico general a través de la aplicación de iPhone iStethoscope Pro.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "def clean_filename(fname, string):\n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':\n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "def load_wav_file(name, path):\n",
    "    s, b = wavfile.read(path + name)\n",
    "    assert s == SAMPLE_RATE\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(a)** Construya un dataframe con los datos a analizar. Describa el dataset y determine cuántos registros hay\n",
    "por clase.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./heartbeat-sounds/set_a.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\">\n",
    "    El _dataset_ posee 176 datos, los cuales poseen 4 columnas cada uno.\n",
    "    <ul style=\"list-style-type:disc;margin-left:24px\">\n",
    "        <li>**dataset:** columna que indica a que dataset corresponde el dato</li>\n",
    "        <li>**fname:** corresponde al nombre del archivo de audio</li>\n",
    "        <li>**label:** puede ser \"normal\", estar en blanco (para datos sin etiqueta), y anormales donde pueden ser \"artifac\", \"extrahls\" y \"murmur\". </li>\n",
    "        <li>**sublabel:** columna sin datos.</li>\n",
    "\n",
    "    </ul>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p  style=\"text-align: justify;\">\n",
    "    Descripcion de las categorias:\n",
    "    <ul style=\"list-style-type:disc;margin-left:24px;text-align: justify;\">\n",
    "        <li>**Normal:** Corresponden a sonidos de corazones normales y saludables.</li>\n",
    "        <li>**Murmur (Soplo):** Corresponden a soplos cardíacos, que suenan como si hubiera un ruido de \"silbido, rugido, estruendo o fluido turbulento\". </li>\n",
    "        <li>**Extra Heart Sound:** Correspoden a una medición en la cual se escucha un sonido adicional del corazón.  </li>\n",
    "        <li>**Artifact:** En esta categoria se encuentra una amplia gama de sonidos diferentes, que incluyen chillidos y ecos de realimentación, voz, música y ruido. Gerenalmente no hay sonidos cardíacos discernibles. Esta categoría es la más diferente de las otras. </li>\n",
    "        <li>**Unlabelled:** Son aquellas muestras que no estan etiquetadas en ninguna categoria. </li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "|     Categoria     \t| Registro \t|\n",
    "|:-----------------:\t|:--------:\t|\n",
    "|       Normal      \t|    31    \t|\n",
    "|       Murmur      \t|    34    \t|\n",
    "| Extra Heart Sound \t|    19    \t|\n",
    "|      Artifact     \t|    40    \t|\n",
    "|     Unlabelled    \t|    52    \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['dataset','sublabel',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Artifact\",df.label.value_counts()['artifact'])\n",
    "print(\"Murmur\", df.label.value_counts()['murmur'])\n",
    "print(\"Extra Heart Sound\", df.label.value_counts()['extrahls'])\n",
    "print(\"Normal\", df.label.value_counts()['normal'])\n",
    "print(\"Unlabelled\", 176-40-34-19-31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(b)** Lea los archivos _.wav_ y transformelos en secuencias de tiempo. Realice un _padding_ de ceros al final de\n",
    "cada secuencia para que todas queden representadas con la misma cantidad de elementos, explique la\n",
    "importancia de realizar este paso.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padd_zeros(array,length):\n",
    "    aux = np.zeros(length)\n",
    "    aux[:array.shape[0]] = array\n",
    "    return aux\n",
    "\n",
    "\n",
    "new_df =pd.DataFrame({'file_name' : df['fname'].apply(clean_filename,string='Aunlabelledtest')})\n",
    "new_df['time_series'] = new_df['file_name'].apply(load_wav_file, path='./heartbeat-sounds/set_a/')\n",
    "new_df['len_series'] = new_df['time_series'].apply(len)\n",
    "new_df['time_series'] = new_df['time_series'].apply(padd_zeros,length=max(new_df['len_series']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(c)** Manipule los datos y cambie las etiquetas de los audios por otras asignadas por un doctor experto,\n",
    "el cual afirma que estos cambios son requeridos. Vuelva a determinar cuántos registros hay por clase.\n",
    "Nótese que ahora son 3 clases ¿Explique la problemática de tener etiquetas mal asignadas en los datos?\n",
    "¿Un solo dato puede afectar esto?\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "             1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
    "             2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
    "             1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0,\n",
    "             2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0, 0, 0,\n",
    "             0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "labels = ['artifact','normal/extrahls', 'murmur']\n",
    "new_df['target'] = [labels[i] for i in new_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Artifact\",new_df.target.value_counts()['artifact'])\n",
    "print(\"Murmur\", new_df.target.value_counts()['murmur'])\n",
    "print(\"Normal and EHSound\", new_df.target.value_counts()['normal/extrahls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          Categoria         \t| Registro \t|\n",
    "|:--------------------------:\t|:--------:\t|\n",
    "| Normal / Extra Heart Sound \t|    65    \t|\n",
    "|           Murmur           \t|    53    \t|\n",
    "|          Artifact          \t|    58    \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(d)**  Codifique las distintas clases a valores numéricos para que puedan ser trabajados por los algoritmos\n",
    "clasificadores.\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"target\"] = new_df[\"target\"].astype('category')\n",
    "cat_columns = new_df.select_dtypes(['category']).columns\n",
    "new_df[cat_columns] = new_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(e)** Desordene los datos, evitando así el orden en el que vienen la gran mayoría de las etiquetas. Cree la\n",
    "matriz que conforma a los datos en sus dimensiones sin preprocesar, es decir, cada ejemplo es una\n",
    "secuencia de amplitudes en el tiempo. ¿Las dimensiones de ésta indica que puede generar problemas?\n",
    "¿De qué tipo?\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.sample(frac=1,random_state=44)\n",
    "X = np.stack(new_df['time_series'].values, axis=0)\n",
    "y = new_df.target.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(f)** Para pre procesar la secuencia en el tiempo realice una Transformada de Fourier discreta para pasar\n",
    "los datos desde el dominio de tiempos al dominio de frecuencias presentes en la señal de sonido.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fourier = np.abs(np.fft.fft(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(g)**  Para seguir con el pre procesamiento realice un muestreo representativo de los datos a través de una\n",
    "técnica de muestreo especializada en secuencias ¿En qué beneficia este paso? ¿Cómo podría determinar\n",
    "si el muestro es representativo?\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "X_resampled = []\n",
    "for i in range(X_fourier.shape[0]):\n",
    "    sequence = X_fourier[i,:].copy()\n",
    "    resampled_sequence = signal.resample(sequence, 100000)\n",
    "    X_resampled.append(resampled_sequence)\n",
    "\n",
    "X_resampled = np.array(X_resampled)\n",
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(h)**  Genere un conjunto de pruebas mediante la técnica _hold-out validation_ para verificar la calidad de los\n",
    "clasificadores. ¿Cuántas clases tiene y de qué tamaño queda cada conjunto?\n",
    "\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y, test_size=0.25, random_state=43)\n",
    "\n",
    "print(\"El set de entrenamiento tiene \" + str(len(X_train)) \n",
    "      + \" y el set de test tiene \" + str(len(X_test)) \n",
    "      + \" datos, y ambos tienen 10000 clases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(i)**  Realice un proceso de estandarizar los datos para ser trabajados adecuadamente. Recuerde que solo se\n",
    "debe ajustar (calcular media y desviación estándar) con el conjunto de entrenamiento.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(j)**  Realice una reducción de dimensionalidad a través de la técnica PCA, para representar los datos en $d = 2$ dimensiones. Recuerde que solo se debe ajustar (encontrar las componentes principales) con el conjunto de entrenamiento. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "d=2\n",
    "pca_model = PCA(n_components=d)\n",
    "pca_model.fit(X_train)\n",
    "X_pca_train = pca_model.transform(X_train)\n",
    "X_pca_test = pca_model.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(k)**  Entrene un modelo de Regresión Logística variando el parámetro de regularización $C$ construyendo un gráfico resumen del error en función de este hiper-parámetro. Además entrene una Máquina de Soporte Vectorial (SVM) con kernel lineal, variando el hiper-parámetro de regularizacion $C$ en el mismo rango que para la Regresión Logística, construyendo el mismo gráfico resumen. Compare.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC as SVM #SVC is for classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mse_LR_train = []\n",
    "mse_LR_test = []\n",
    "\n",
    "mse_SVM_train = []\n",
    "mse_SVM_test = []\n",
    "\n",
    "Ks = []\n",
    "Ks_ticks = [0.0001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "for i, Cs in enumerate((0.0001,0.01,0.1,1,10,100,1000)):\n",
    "    \n",
    "    model_LR = LR(C=Cs)\n",
    "    model_SVM = SVM(C=Cs)\n",
    "    \n",
    "    model_LR.fit(X_pca_train, y_train)\n",
    "    model_SVM.fit(X_pca_train, y_train)\n",
    "    \n",
    "    y_pred_LR_train = model_LR.predict(X_pca_train)\n",
    "    y_pred_LR_test = model_LR.predict(X_pca_test)\n",
    "    \n",
    "    y_pred_SVM_train = model_SVM.predict(X_pca_train)\n",
    "    y_pred_SVM_test = model_SVM.predict(X_pca_test)\n",
    "\n",
    "    mse_LR_train.append(1-accuracy_score(y_train, y_pred_LR_train))\n",
    "    mse_LR_test.append(1-accuracy_score(y_test, y_pred_LR_test))\n",
    "    \n",
    "    mse_SVM_train.append(1-accuracy_score(y_train, y_pred_SVM_train))\n",
    "    mse_SVM_test.append(1-accuracy_score(y_test, y_pred_SVM_test))\n",
    "    \n",
    "    Ks.append(i+1)\n",
    "    \n",
    "    #print(\"Miss Classification Loss for LR: %f\"%(1-accuracy_score(y_train, y_pred_LR)))\n",
    "    #print(\"Miss Classification Loss for SVM: %f\"%(1-accuracy_score(y_train, y_pred_SVM)))\n",
    "    \n",
    "    #print(\"C=%.5f\" % Cs)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "LR_plot = plt.subplot(2,1,1)\n",
    "LR_plot.plot(Ks, mse_LR_train, label='LR Training Misclassification Error')\n",
    "LR_plot.plot(Ks, mse_LR_test, label='LR Testing Misclassification Error')\n",
    "plt.legend(loc=3)\n",
    "plt.xlabel('Parámetro Regularizador $C$')\n",
    "plt.ylabel('Miss Classification Error')\n",
    "plt.axis([1,6,0.0, 0.7])\n",
    "plt.xticks(Ks, Ks_ticks)\n",
    "\n",
    "SVM_plot = plt.subplot(2,1,2)    \n",
    "SVM_plot.plot(Ks, mse_SVM_train, label = 'SVM Training Misclassification Error')\n",
    "SVM_plot.plot(Ks, mse_SVM_test, label = 'SVM Test Misclassification Error')\n",
    "plt.legend(loc=3)\n",
    "plt.xlabel('Parámetro Regularizador $C$')\n",
    "plt.ylabel('Miss Classification Error')\n",
    "plt.axis([1,6,0.0, 0.7])\n",
    "plt.xticks(Ks, Ks_ticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.xlabel('Parametro Regularización $C$')\n",
    "#plt.ylabel('Miss Classification Error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(l)**  Entrene un Arbol de Decisión, con la configuración que estime conveniente, variando el hiper-parámetro regularizador _max depth_, construyendo un gráfico resumen del error en función de este parámetro.\n",
    "Compare con los modelos anteriores.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "Depths = range(1,30)\n",
    "\n",
    "mse_DTC_train = []\n",
    "mse_DTC_test = []\n",
    "\n",
    "for i in Depths:\n",
    "    model_DTC = DTC(max_depth = i)\n",
    "    \n",
    "    model_DTC.fit(X_pca_train, y_train)\n",
    "    \n",
    "    y_pred_DTC_train = model_DTC.predict(X_pca_train)\n",
    "    y_pred_DTC_test = model_DTC.predict(X_pca_test)\n",
    "    \n",
    "    mse_DTC_train.append(1-accuracy_score(y_train, y_pred_DTC_train))\n",
    "    mse_DTC_test.append(1-accuracy_score(y_test, y_pred_DTC_test))\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "DTC_plot = plt.subplot(1,1,1)\n",
    "DTC_plot.plot(Depths, mse_DTC_train, label='Training Misclassification Error')\n",
    "DTC_plot.plot(Depths, mse_DTC_test, label='Testing Misclassification Error')\n",
    "plt.legend(loc=3)\n",
    "plt.ylabel('Miss Classification Error')\n",
    "plt.axis([0,30,0.0, 0.7])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(m)**  Experimente con diferentes dimensiones $d$ para la proyección de PCA con el propósito de obtener un\n",
    "modelo con menor error. Construya una tabla o gráfico resumen.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plots_MCE_PCA(D, C_LR, C_SVM):\n",
    "    mse_LR_train = []\n",
    "    mse_LR_test = []\n",
    "    mse_SVM_train = []\n",
    "    mse_SVM_test = []\n",
    "\n",
    "    model_LR = LR(C=1000)\n",
    "    model_SVM = SVM(C=1)\n",
    "\n",
    "    dim = np.arange(1,D)\n",
    "\n",
    "    for d in range(1,D):\n",
    "\n",
    "        pca_model = PCA(n_components=d)\n",
    "        pca_model.fit(X_train)\n",
    "\n",
    "        X_pca_train = pca_model.transform(X_train)\n",
    "        X_pca_test = pca_model.transform(X_test)\n",
    "\n",
    "        model_LR.fit(X_pca_train, y_train)\n",
    "        model_SVM.fit(X_pca_train, y_train)\n",
    "\n",
    "        y_pred_LR_train = model_LR.predict(X_pca_train)\n",
    "        y_pred_LR_test = model_LR.predict(X_pca_test)\n",
    "\n",
    "        y_pred_SVM_train = model_SVM.predict(X_pca_train)\n",
    "        y_pred_SVM_test = model_SVM.predict(X_pca_test)\n",
    "\n",
    "        mse_LR_train.append(1-accuracy_score(y_train, y_pred_LR_train))\n",
    "        mse_LR_test.append(1-accuracy_score(y_test, y_pred_LR_test))\n",
    "        mse_SVM_train.append(1-accuracy_score(y_train, y_pred_SVM_train))\n",
    "        mse_SVM_test.append(1-accuracy_score(y_test, y_pred_SVM_test))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(18,12))\n",
    "\n",
    "    LR_plot = plt.subplot(2,1,1)\n",
    "    LR_plot.plot(dim, mse_LR_train, label='LR Training Misclassification Error')\n",
    "    LR_plot.plot(dim, mse_LR_test, label='LR Testing Misclassification Error')\n",
    "    plt.legend(loc='center right')\n",
    "    plt.xlabel('Dimensiones')\n",
    "    plt.ylabel('Miss Classification Error')\n",
    "\n",
    "    SVM_plot = plt.subplot(2,1,2)    \n",
    "    SVM_plot.plot(dim, mse_SVM_train, label = 'SVM Training Misclassification Error')\n",
    "    SVM_plot.plot(dim, mse_SVM_test, label = 'SVM Test Misclassification Error')\n",
    "    plt.legend(loc='center right')\n",
    "    plt.xlabel('Dimensiones')\n",
    "    plt.ylabel('Miss Classification Error')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.xlabel('Parametro Regularización $C$')\n",
    "    #plt.ylabel('Miss Classification Error')\n",
    "\n",
    "    plt.show()  \n",
    "\n",
    "widgets.interact(plots_MCE_PCA,D = (1,20),C_LR = (1,1000,1),C_SVM=(1,1000,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(n)**  Realice otra reducción de dimensionalidad ahora a través de la técnica LDA, para representar los datos en $d = 2$ dimensiones. Recuerde que sólo se debe ajustar con el conjunto de entrenamiento, si se muestra un warning explique el porqué. Visualice apropiadamente la proyección en $2$ dimensiones.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "model_lda = LDA(n_components=2)\n",
    "model_lda.fit(X_train,y_train)\n",
    "X_pca_train = model_lda.transform(X_train)\n",
    "X_pca_test = model_lda.transform(X_test)\n",
    "\n",
    "plot(X_pca_train, y_train)\n",
    "plot(X_pca_test, y_test)\n",
    "\n",
    "#y_pred_lda = model_lda.predict(X_pca_train)\n",
    "\n",
    "#visualize_border(model_lda, X_train, y_train,\"LDA\")\n",
    "#print(X_pca_train)\n",
    "#https://stats.stackexchange.com/questions/29385/collinear-variables-in-multiclass-lda-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(o)**  Con el propósito de encontrar el mejor modelo vuelva a realizar el item h) con el i) en el nuevo espacio generado por la representación según las d dimensiones de la proyección LDA. Esta nueva representación ¿mejora o empeora el desempeño? Explique.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y, test_size=0.25, random_state=43)\n",
    "model_lda = LDA(n_components=2)\n",
    "model_lda.fit(X_train,y_train)\n",
    "X_pca_train = model_lda.transform(X_train)\n",
    "X_pca_test = model_lda.transform(X_test)\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_pca_train)\n",
    "X_train = std.transform(X_pca_train)\n",
    "X_test = std.transform(X_pca_test)\n",
    "\n",
    "plot(X_train, y_train)\n",
    "plot(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "   Mejora la situación, debido a que los límites en donde están distribuidos los data sets disminuyeron.\n",
    "   <ul>\n",
    "       <li>Gráfico 1:\n",
    "           <ul>\n",
    "             <li>Eje $y$: de 4 a 1.5 en el límite superior y de -3 a -1 en el límite inferior</li>\n",
    "             <li>Eje $x$: de 4 a 1 en el límite superior y de -6 a -1.5 en el límite inferior</li>\n",
    "           </ul>\n",
    "       </li>\n",
    "       <li>Gráfico 2:\n",
    "            <ul>\n",
    "             <li>Eje $y$: de 150 a 60 en el límite superior y de -200 a -80 en el límite inferior</li>\n",
    "             <li>Eje $x$: de 200 a 50 en el límite superior y de -600 a -150 en el límite inferior</li>\n",
    "           </ul>\n",
    "       </li>\n",
    "   </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(p)**  Intente mejorar el desempeño de los algoritmos ya entrenados. Diseñe ahora sus propias características (_feature crafting_) a partir de los datos brutos (secuencia de amplitudes), puede inspirarse en otros trabajos [6] [7] si desea.\n",
    "</p>\n",
    "\n",
    "- [6]  https://www.kaggle.com/primaryobjects/voicegender/data\n",
    "- [7]  Gamit, M. R., Dhameliya, P. K., & Bhatt, N. S. (2015). Classification Techniques for Speech Recognition: A Review. vol, 5, 58-63.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Análisis de emociones en tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(a)**  Construya un dataframe con los datos a analizar. Determine cuántas clases existen, cuántos registros por clase y describa el _dataset_.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_csv('./text_emotion.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Sentimiento | Registro |\n",
    "|:-----------:|:--------:|\n",
    "|   Neutral   |   8638   |\n",
    "|    Worry    |   8459   |\n",
    "|  Happiness  |   5209   |\n",
    "|   Sadness   |   5165   |\n",
    "|     Love    |   3842   |\n",
    "|   Surprise  |   2187   |\n",
    "|     Fun     |   1776   |\n",
    "|    Relief   |   1526   |\n",
    "|     Hate    |   1323   |\n",
    "|    Empty    |    827   |\n",
    "|  Enthusiasm |    759   |\n",
    "|   Boredom   |    179   |\n",
    "|    Anger    |    110   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(b)**  Construya un conjunto de entrenamiento y otro de pruebas, a través de una máscara aleatoria, para verificar los resultados de los algoritmos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(22)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y, test_size=0.25, random_state=43)\n",
    "\n",
    "#print(df['content'][2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(c)**  Implemente y explique un pre-procesamiento para los tweets para dejarlos en un formato estándarizado\n",
    "en el cual se podrán trabajar.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['tweet_id','author'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\[\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "\n",
    "\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "#print(preprocess(df['content'][0]))\n",
    "\n",
    "#df['content'] = df['content'].str\n",
    "df['content'] = df['content'].apply(preprocess)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"rt\",\"via\",\"a\",\"able\",\"about\",\"across\",\"after\",\"all\",\"almost\",\"also\",\"am\",\"among\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"but\",\"by\",\"can\",\"cannot\",\"could\",\"dear\",\"did\",\"do\",\"does\",\"either\",\"else\",\"ever\",\"every\",\"for\",\"from\",\"get\",\"got\",\"had\",\"has\",\"have\",\"he\",\"her\",\"hers\",\"him\",\"his\",\"how\",\"however\",\"i\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"least\",\"let\",\"like\",\"likely\",\"may\",\"me\",\"might\",\"most\",\"must\",\"my\",\"neither\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"often\",\"on\",\"only\",\"or\",\"other\",\"our\",\"own\",\"rather\",\"said\",\"say\",\"says\",\"she\",\"should\",\"since\",\"so\",\"some\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\"these\",\"they\",\"this\",\"tis\",\"to\",\"too\",\"twas\",\"us\",\"wants\",\"was\",\"we\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"would\",\"yet\",\"you\",\"your\"]\n",
    "stop = stopwords.words('english')\n",
    "result = list(set(stop)|set(stop_words)|set(list('abcdefghijklmnopqrstuvwxyz')) | set(list('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')) | set(list('0123456789')))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: [item for item in x if item not in result])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(d)**  Haga una reducción binaria al problema, para trabajarlo como un problema de clasificación de dos clases.\n",
    "Para esto, agrupe las distintas emociones como positivas y negativas (defina un criterio), se recomienda\n",
    "codificar las clases como +1 y −1 respectivamente. Recuerde tener presente que el desbalanceo de los\n",
    "datos puede afectar considerablemente al modelo.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uno = ['happiness', 'love', 'fun', 'relief', 'enthusiasm']\n",
    "\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x in uno else -1)\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(e)**  Para construir un clasificador que determine automáticamente la polaridad de un trozo de texto, será\n",
    "necesario representar los tweets $\\{t_i\\}_{i=1}^{n}$ disponibles como vectores de características (features). El tipo\n",
    "de características más utilizado consiste en contar cuántas veces aparecen ciertos términos/palabras en\n",
    "el texto. Para esto, es necesario un vocabulario que, por lo general, se construye mediante la unión de\n",
    "todas las palabras que se observen en los tweets.\n",
    "\n",
    "</p>\n",
    "<p  style=\"text-align: justify;\">\n",
    "Se recomienda utilizar las librerías ofrecidas por sklearn de feature extraction in text [12] (_CountVectorizer_ y _TfidfVectorizer_). Recuerde realizar el ajuste (_fit_) únicamente con el conjunto de entrenamiento, para luego transformar el conjunto de pruebas (con el método transform).\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "- [12] http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "X = df['content'].values\n",
    "y = df.sentiment.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "\n",
    "def fake(x):\n",
    "    return x\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=fake, preprocessor=fake, lowercase=False)\n",
    "\n",
    "#vectorizer = CountVectorizer(tokenizer=tokenizr, preprocessor=PP, lowercase=False)\n",
    "#CV_fit = CV_model.fit_transform(X_train.tostring())\n",
    "#X_CV_train = CV_model.transform(X_train)\n",
    "\n",
    "X_CV_train = vectorizer.fit_transform(X_train)\n",
    "X_CV_test = vectorizer.transform(X_test)\n",
    "\n",
    "type(X_CV_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(X_train.toarray(), df_train['sentiment'])\n",
    "\n",
    "qda_score_train = qda_model.score(X_train.toarray(), df_train['sentiment'])\n",
    "qda_score_test = qda_model.score(X_test.toarray(), df_test['sentiment'])\n",
    "\n",
    "print(\"NB Train score %f\"%qda_score_train)\n",
    "print(\"NB Test score %f\"%qda_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train.toarray(), df_train['sentiment'])\n",
    "\n",
    "lda_score_train = lda_model.score(X_train, df_train['sentiment'])\n",
    "lda_score_test = lda_model.score(X_test, df_test['sentiment'])\n",
    "\n",
    "print(\"NB Train score %f\"%lda_score_train)\n",
    "print(\"NB Test score %f\"%lda_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(f)**  Entrene y compare al menos 5 de los diferentes clasificadores vistos en clases para clasificación binaria (por ejemplo: Navie Bayes, Multinomial Naive Bayes, LDA, QDA, Regresión logística, SVM y Arboles de decisión) sobre el conjunto de entrenamiento verificando su desempeño sobre ambos conjuntos (entrenamiento y de pruebas), construyendo un gráfico resumen del error de éstos.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_model = BernoulliNB()\n",
    "nb_model.fit(X_CV_train, y_train)\n",
    "\n",
    "nb_score_train = nb_model.score(X_CV_train, y_train)\n",
    "nb_score_test = nb_model.score(X_CV_test, y_test)\n",
    "\n",
    "print(\"NB Train score %f\"%nb_score_train)\n",
    "print(\"NB Test score %f\"%nb_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "DTC_model = DTC()\n",
    "DTC_model.fit(X_CV_train, y_train)\n",
    "\n",
    "DTC_score_train = DTC_model.score(X_CV_train, y_train)\n",
    "DTC_score_test = DTC_model.score(X_CV_test, y_test)\n",
    "\n",
    "print(\"DTC Train score %f\"%DTC_score_train)\n",
    "print(\"DTC Test score %f\"%DTC_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "LR_model = LR()\n",
    "LR_model.fit(X_CV_train, y_train)\n",
    "\n",
    "LR_score_train = LR_model.score(X_CV_train, y_train)\n",
    "LR_score_test = LR_model.score(X_CV_test, y_test)\n",
    "\n",
    "print(\"LR Train score %f\"%LR_score_train)\n",
    "print(\"LR Test score %f\"%LR_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC as SVC #SVC is for classification\n",
    "SVC_model = SVC()\n",
    "SVC_model.fit(X_CV_train, y_train)\n",
    "\n",
    "SVC_score_train = SVC_model.score(X_CV_train, y_train)\n",
    "SVC_score_test = SVC_model.score(X_CV_test, y_test)\n",
    "\n",
    "print(\"SVC Train score %f\"%SVC_score_train)\n",
    "print(\"SVC Test score %f\"%SVC_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "KNC_model = KNC()\n",
    "KNC_model.fit(X_CV_train, y_train)\n",
    "\n",
    "KNC_score_train = KNC_model.score(X_CV_train, y_train)\n",
    "KNC_score_test = KNC_model.score(X_CV_test, y_test)\n",
    "\n",
    "print(\"KNC Train score %f\"%KNC_score_train)\n",
    "print(\"KNC Test score %f\"%KNC_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "MLPC_model = MLPC()\n",
    "MLPC_model.fit(X_CV_train, y_train)\n",
    "\n",
    "MLPC_score_train = MLPC_model.score(X_CV_train, y_train)\n",
    "MLPC_score_test = MLPC_model.score(X_CV_test, y_test)\n",
    "\n",
    "print(\"MLPC Train score %f\"%MLPC_score_train)\n",
    "print(\"MLPC Test score %f\"%MLPC_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(g)**  Utilice y explique las métricas que calcula la función classification report de la librería sklearn. En base\n",
    "a las distintas métricas calculadas ¿Cuáles clasificadores son los que mejor se comportan?\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy: %f\"%(acc_tr)\n",
    "    print \"Test Accuracy: %f\"%(acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(y_test, model.predict(X_test), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(h)**  [Opcional] Visualice las predicciones de algún modelo generativo (probabilístico) definido anteriormente, tomando un subconjunto aleatorio de tweets de pruebas y explorando las probabilidades que asigna el clasificador a cada clase.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict_proba(X_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(df_test.content[spl], test_pred[spl]):\n",
    "    print sentiment, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(i)**  Ahora deberá extender el problema a las múltiples clases que tiene presente (las distintas emociones),\n",
    "es decir, su trabajo será el de predecir una de las distintas emociones de cada _tweet_. Para esto utilice el\n",
    "mismo pre-procesamiento realizado en el punto c) y las características generadas mediante las técnicas\n",
    "en el punto e). Recuerde que tendrá que codificar las distintas clases como valores numéricos enteros.\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(j)**  Utilice los clasificadores que son extendidos por defecto a múltiples clases para detectar emociones en\n",
    "cada _tweet_, muestre sus desempeños a través del error de pruebas en un gráfico resumen.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(k)**  Utilice clasificadores binarios que pueden ser extendidos a través de otras técnicas, tal como One vs\n",
    "One y One vs All/Rest [14]\n",
    "</p>\n",
    "\n",
    "- [14]  http://scikit-learn.org/stable/modules/classes.html#module-sklearn.multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "#example\n",
    "classif = OneVsRestClassifier(model)\n",
    "classif.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(l)**  Para el caso de la Regresión Logística compare sus dos métodos para ser extendidos a múltiples clases.\n",
    "Uno a través de One vs Rest y otro definiendo que la variable a predecir se distribuye Multinomial.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LogisticRegression(multi_class='ovr')\n",
    "LogisticRegression(multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p  style=\"text-align: justify;\"> \n",
    "    **(m)**  Compare los resultados entre los clasificadores extendidos por defecto y los binarios que son extendidos mediante otras técnicas, construya una tabla o gráfico resumen. Los clasificadores que mejor se comportan en el caso binario ¿Siguen teniendo ese desempeño en múltiples clases?\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
